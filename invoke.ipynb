{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key =\"sk-None-\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murugan\\AppData\\Local\\Temp\\ipykernel_35448\\3607154471.py:22: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
      "C:\\Users\\murugan\\AppData\\Local\\Temp\\ipykernel_35448\\3607154471.py:38: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first client name mentioned is Teleah Grand. She is associated with the patient Buckshot, a French Bulldog. This information was retrieved from the Animal Care Center at Stonebridge Ranch records.\n",
      "The first client phone number mentioned is 214-563-1688. This number is listed as the emergency contact for Teleah Grand. She is associated with the patient Buckshot, a French Bulldog.\n",
      "The first patient name mentioned is Buckshot. Buckshot is a French Bulldog owned by Teleah Grand. This information is recorded in the Animal Care Center at Stonebridge Ranch medical chart.\n",
      "The only patient name mentioned in the provided context is Buckshot. Buckshot is a French Bulldog owned by Teleah Grand. There are no additional patient names listed in the retrieved context.\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "file_path = \"D:\\\\muthukumar\\\\ocr\\\\extracted_text.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "text_chunks = text_splitter.split_text(text_content)\n",
    "documents = [Document(page_content=chunk, metadata={\"source\": file_path}) for chunk in text_chunks]\n",
    "\n",
    "def prompt_function(documents, api_key):\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "    vectorstore = FAISS.from_documents(documents, embedding=embeddings)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        <s> [INST] You are an assistant for question-answering tasks. Use the following pieces of retrieved context \n",
    "        to answer the question. If you don't know the answer, just say that you don't know. Use three sentences\n",
    "        maximum and keep the answer concise. If there is previous context provided, incorporate it into your response. [/INST] </s> \n",
    "        [INST] Previous context: {previous_context}\n",
    "        Question: {input}\n",
    "        Context: {context}\n",
    "        Answer: [/INST]\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "        openai_api_key=api_key,\n",
    "        max_retries=10\n",
    "    )\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "    return retrieval_chain\n",
    "\n",
    "api_key = api_key  # Replace with  API key\n",
    "retrieval_chain = prompt_function(documents, api_key)\n",
    "\n",
    "previous_context = \"\"\n",
    "\n",
    "while True:\n",
    "    question = input(\"Enter your question (or type 'exit' to quit): \")\n",
    "    if question.lower() == \"exit\":\n",
    "        break\n",
    "    \n",
    "    response = retrieval_chain.invoke({\"input\": question, \"previous_context\": previous_context})\n",
    "    \n",
    "    print(response['answer'])\n",
    "    previous_context += f\"\\n{response}\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
